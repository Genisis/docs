<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head xmlns="http://www.w3.org/1999/xhtml"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Map/Reduce integration</title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch Hadoop" /><link rel="up" href="_reference.html" title="Reference" /><link rel="prev" href="runtime-configuration.html" title="Hadoop runtime options" /><link rel="next" href="cascading.html" title="Cascading support" /><script xmlns="" type="text/javascript" src="http://www.elasticsearch.org/wp-includes/js/jquery/jquery.js?ver=1.8.3"></script><link xmlns="" rel="stylesheet" id="prettify-gc-syntax-highlighter-css" href="http://www.elasticsearch.org/content/plugins/prettify-gc-syntax-highlighter/prettify.css?ver=3.5.2" type="text/css" media="all" /><link xmlns="" rel="stylesheet" id="appStyles-css" href="http://www.elasticsearch.org/content/themes/elasticsearch-org/css/main.css?ver=1376314515" type="text/css" media="all" /><script xmlns="" type="text/javascript" src="http://www.elasticsearch.org/content/themes/elasticsearch-org/js/vendor/modernizr-2.6.1.min.js?ver=1"></script><script xmlns="" type="text/javascript" src="http://www.elasticsearch.org/content/themes/elasticsearch-org/js/vendor/selectivizr-min.js?ver=1"></script><script xmlns="" type="text/javascript" src="http://www.elasticsearch.org/content/themes/elasticsearch-org/js/plugins.min.js?ver=1375472072"></script><link xmlns="" rel="stylesheet" type="text/css" href="styles.css" /></head><body class="single single-guide"><div class="global_wrapper"><div id="index" class="page_content"><div class="container"><section class="full_width guide"><article class="guide_content"><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Hadoop</a></span> &gt; <span class="breadcrumb-link"><a href="_reference.html">Reference</a></span> &gt; <span class="breadcrumb-node">Map/Reduce integration</span></div><div class="navheader"><span class="prev"><a href="runtime-configuration.html">
              « 
              Hadoop runtime options</a>
           
        </span><span class="next">
           
          <a href="cascading.html">Cascading support
               » 
            </a></span></div><div xmlns="http://www.w3.org/1999/xhtml" class="chapter"><div class="titlepage"><div><div><h2 class="title"><a id="mapreduce"></a>Map/Reduce integration</h2></div></div></div><div xmlns="" class="toc"><dl><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="configuration.html">Configuration options</a></span></dt><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="runtime-configuration.html">Hadoop runtime options</a></span></dt><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="mapreduce.html">Map/Reduce integration</a></span></dt><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="cascading.html">Cascading support</a></span></dt><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="hive.html">Apache Hive integration</a></span></dt><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="pig.html">Apache Pig support</a></span></dt><dt xmlns="http://www.w3.org/1999/xhtml"><span class="chapter"><a href="mapping.html">Mapping and Type conversion</a></span></dt></dl></div><p>For low-level or performance-sensitive environments, Elasticsearch Hadoop provides dedicated <code class="literal">InputFormat</code> and <code class="literal">OutputFormat</code> implementations that can read and write data to Elasticsearch. The two IO interfaces will automatically convert JSON documents to <code class="literal">Map</code> of <code class="literal">Writable</code> objects and vice-versa.</p><h3><a id="_installation"></a>Installation</h3><p>In order to use Elasticsearch Hadoop, the jar needs to be available to the job class path. At ~<code class="literal">150kB</code> and without any dependencies, the jar can be either bundled in the job archive, manually or through CLI <a class="ulink" href="http://hadoop.apache.org/docs/r1.2.1/commands_manual.html#Generic`Options" target="_top">Generic Options</a> (if your jar implements the <a class="ulink" href="http://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/util/Tool.html" target="_top">Tool</a>), be distributed through Hadoop’s <a class="ulink" href="http://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html#DistributedCache" target="_top">DistributedCache</a> or made available by provisioning the cluster manually.</p><p><strong>CLI example. </strong>
</p><pre class="programlisting prettyprint noescape lang-bash">$ bin/hadoop jar myJar.jar -libjars elasticsearch-hadoop.jar</pre><p>
</p><h3><a id="type-conversion-writable"></a>Type conversion</h3><div class="important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>If automatic index creation is used, please review <a class="link" href="_automatic_mapping.html#auto-mapping-type-loss">this</a> section for more information.</p></td></tr></table></div><p>Elasticsearch Hadoop automatically converts Hadoop built-in <code class="literal">Writable</code> types to Elasticsearch <a class="ulink" href="http://www.elasticsearch.org/guide/reference/mapping/core-types/" target="_top">types</a> (and back) as shown in the table below:</p><div class="table"><a id="idp36337744"></a><p class="title"><strong>Table 1. <code class="literal">Writable</code> Conversion Table</strong></p><div class="table-contents"><table summary="Writable Conversion Table" cellpadding="4px" border="1"><colgroup><col class="col_1" /><col class="col_2" /></colgroup><thead><tr><th align="center" valign="top"> <code class="literal">Writable</code> </th><th align="center" valign="top"> Elasticsearch type</th></tr></thead><tbody><tr><td align="center" valign="top"><p><code class="literal">null</code></p></td><td align="center" valign="top"><p><code class="literal">null</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">NullWritable</code></p></td><td align="center" valign="top"><p><code class="literal">null</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">Text</code></p></td><td align="center" valign="top"><p><code class="literal">string</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">UTF8</code></p></td><td align="center" valign="top"><p><code class="literal">string</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">ByteWritable</code></p></td><td align="center" valign="top"><p><code class="literal">byte</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">IntWritable</code></p></td><td align="center" valign="top"><p><code class="literal">int</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">VInt</code></p></td><td align="center" valign="top"><p><code class="literal">int</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">LongWritable</code></p></td><td align="center" valign="top"><p><code class="literal">long</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">VLongWritable</code></p></td><td align="center" valign="top"><p><code class="literal">long</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">ByteWritable</code></p></td><td align="center" valign="top"><p><code class="literal">binary</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">DoubleWritable</code></p></td><td align="center" valign="top"><p><code class="literal">double</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">FloatWritable</code></p></td><td align="center" valign="top"><p><code class="literal">float</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">BooleanWritable</code></p></td><td align="center" valign="top"><p><code class="literal">boolean</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">MD5Writable</code></p></td><td align="center" valign="top"><p><code class="literal">string</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">ArrayWritable</code></p></td><td align="center" valign="top"><p><code class="literal">array</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">AbstractMapWritable</code></p></td><td align="center" valign="top"><p><code class="literal">map</code></p></td></tr></tbody></table></div></div><br class="table-break" /><h3><a id="_writing_data_to_elasticsearch"></a>Writing data to Elasticsearch</h3><p>With Elasticsearch Hadoop, Map/Reduce jobs can write data to Elasticsearch making it searchable through <a class="ulink" href="http://www.elasticsearch.org/guide/reference/glossary/#index" target="_top">indexes</a>. Elasticsearch Hadoop supports both (so-called)  <a class="ulink" href="http://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/mapred/package-use.html" target="_top"><span class="emphasis"><em>old</em></span></a> and <a class="ulink" href="http://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/mapreduce/package-use.html" target="_top"><span class="emphasis"><em>new</em></span></a> Hadoop APIs.</p><p><code class="literal">ESOutputFormat</code> expects a <code class="literal">Map&lt;Writable, Writable&gt;</code> value that it will convert into a JSON document; the key is ignored.</p><h4><a id="_emphasis_old_emphasis_literal_org_apache_hadoop_mapred_literal_api"></a><span class="emphasis"><em>Old</em></span> (<code class="literal">org.apache.hadoop.mapred</code>) API</h4><p>To write data to ES, use <code class="literal">org.elasticsearch.hadoop.mr.ESOutputFormat</code> on your job along with the relevant configuration <a class="link" href="configuration.html" title="Configuration options">properties</a>:</p><pre class="programlisting prettyprint noescape lang-java">JobConf conf = new JobConf();
conf.setSpeculativeExecution(false);            // disable speculative execution when writing to ES
conf.set("es.resource", "radio/artists");       // index used for storing data
conf.setOutputFormat(ESOutputFormat.class);     // use dedicated output format
...
JobClient.runJob(conf);</pre><h4><a id="_emphasis_new_emphasis_literal_org_apache_hadoop_mapreduce_literal_api"></a><span class="emphasis"><em>New</em></span> (<code class="literal">org.apache.hadoop.mapreduce</code>) API</h4><p>Using the <span class="emphasis"><em>new</em></span> is strikingly similar - in fact, the exact same class (<code class="literal">org.elasticsearch.hadoop.mr.ESOutputFormat</code>) is used:</p><pre class="programlisting prettyprint noescape lang-java">Configuration conf = new Configuration();
conf.set("es.resource", "radio/artists");       // index used for storing data
// disable speculative execution when writing to ES
conf.setBoolean("mapred.map.tasks.speculative.execution", false);
conf.setBoolean("mapred.reduce.tasks.speculative.execution", false);
Job job = new Job(conf);
job.setOutputFormat(ESOutputFormat.class);      // use dedicated output format
...
job.waitForCompletion(true);</pre><h3><a id="_reading_data_from_elasticsearch"></a>Reading data from Elasticsearch</h3><p>In a similar fashion, to read data from Elasticsearch, one needs to use <code class="literal">org.elasticsearch.hadoop.mr.ESInputFormat</code> class.
While it can read an entire index, it is much more convenient to actually execute a query and then feed the results back to Hadoop.</p><p><code class="literal">ESInputFormat</code> returns a <code class="literal">Map&lt;Writable, Writable&gt;</code> converted from the JSON documents returned by Elasticsearch and a null (to be ignored) key.</p><h4><a id="_emphasis_old_emphasis_literal_org_apache_hadoop_mapred_literal_api_2"></a><span class="emphasis"><em>Old</em></span> (<code class="literal">org.apache.hadoop.mapred</code>) API</h4><p>Following our example above on radio artists, to get a hold of all the artists that start with <span class="emphasis"><em>me</em></span>, one could use the following snippet:</p><pre class="programlisting prettyprint noescape lang-java">JobConf conf = new JobConf();
conf.set("es.resource", "radio/artists/_search?q=me*"); // replace this with the relevant query
conf.setInputFormat(ESInputFormat.class);               // use dedicated input format
...
JobClient.runJob(conf);</pre><h4><a id="_emphasis_new_emphasis_literal_org_apache_hadoop_mapreduce_literal_api_2"></a><span class="emphasis"><em>New</em></span> (<code class="literal">org.apache.hadoop.mapreduce</code>) API</h4><p>As expected, the <code class="literal">mapreduce</code> API version is quite similar:</p><pre class="programlisting prettyprint noescape lang-java">Configuration conf = new Configuration();
conf.set("es.resource", "radio/artists/_search?q=me*"); // replace this with the relevant query
Job job = new Job(conf);                                // use dedicated input format
job.setInputFormat(ESInputFormat.class);
...
job.waitForCompletion(true);</pre></div><div class="navfooter"><span class="prev"><a href="runtime-configuration.html">
              « 
              Hadoop runtime options</a>
           
        </span><span class="next">
           
          <a href="cascading.html">Cascading support
               » 
            </a></span></div></article></section></div></div></div><script type="text/javascript" src="http://www.elasticsearch.org/content/plugins/prettify-gc-syntax-highlighter/prettify.js?ver=3.5.2"></script><script type="text/javascript" src="http://www.elasticsearch.org/content/plugins/prettify-gc-syntax-highlighter/launch.js?ver=3.5.2"></script></body></html>
